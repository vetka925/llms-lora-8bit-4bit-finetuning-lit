{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching /usr/local/cuda/lib64...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 6.1\n",
      "CUDA SETUP: Detected CUDA version 117\n",
      "CUDA SETUP: Loading binary /home/vetka/miniconda3/envs/transformers/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda117_nocublaslt.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vetka/miniconda3/envs/transformers/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: /home/vetka/miniconda3/envs/transformers did not contain libcudart.so as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/home/vetka/miniconda3/envs/transformers/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('unix')}\n",
      "  warn(msg)\n",
      "/home/vetka/miniconda3/envs/transformers/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('VSCODE_WSL_EXT_LOCATION/up')}\n",
      "  warn(msg)\n",
      "/home/vetka/miniconda3/envs/transformers/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('vs/workbench/api/node/extensionHostProcess')}\n",
      "  warn(msg)\n",
      "/home/vetka/miniconda3/envs/transformers/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//matplotlib_inline.backend_inline'), PosixPath('module')}\n",
      "  warn(msg)\n",
      "/home/vetka/miniconda3/envs/transformers/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: Compute capability < 7.5 detected! Only slow 8-bit matmul is supported for your GPU!\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wandb\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import pandas as pd\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "import torch \n",
    "from tqdm import tqdm\n",
    "\n",
    "from custom_datasets import PromptDataset\n",
    "from finetuners import FinetunerConfig, GPTJ4bitFineTuner, GPTJ8bitFineTuner, LLaMA4bitFineTuner, LLaMA8bitFineTuner\n",
    "\n",
    "\n",
    "LLAMA_7B_MODEL_PATH = 'decapoda-research/llama-7b-hf'\n",
    "# !wget https://huggingface.co/decapoda-research/llama-7b-hf-int4/resolve/main/llama-7b-4bit.pt\n",
    "LLAMA_7B_4BIT_CHECKPOINT_PATH = './llama-7b-4bit.pt'\n",
    "\n",
    "LLAMA_13B_MODEL_PATH = 'decapoda-research/llama-13b-hf'\n",
    "# !wget https://huggingface.co/decapoda-research/llama-13b-hf-int4/resolve/main/llama-13b-4bit.pt\n",
    "LLAMA_13B_4BIT_CHECKPOINT_PATH = './llama-13b-4bit.pt'\n",
    "\n",
    "GPTJ_6B_MODEL_PATH = 'EleutherAI/gpt-j-6B'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The article on [Medium](https://medium.com/@vitaley.grechachin/how-to-train-a-capable-gpt-3-model-at-home-9c5b400ca7f), [Habr]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data\n",
    "## Required Data:\n",
    " * train and/or validation pandas DataFrame with two columns: prompt, completion\n",
    " * prompt + completion length must be less than 2048 tokens\n",
    " * For classification metrics completion must be 1 token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>offensive</td>\n",
       "      <td>RT @RAYCHIELOVESU: No &amp;#8220;@3rdeyechillin: T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>&amp;#8220;@__Black_Jesus: &amp;#8220;@lil_aerii: Happ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hate</td>\n",
       "      <td>&amp;#8220;@iamkrause: No need to thank me, killin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>offensive</td>\n",
       "      <td>RT @tr4pb0y: when the pussy so good &amp;amp; u fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>offensive</td>\n",
       "      <td>I talk to these bitches like I really do care.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               text\n",
       "0  offensive  RT @RAYCHIELOVESU: No &#8220;@3rdeyechillin: T...\n",
       "1    neutral  &#8220;@__Black_Jesus: &#8220;@lil_aerii: Happ...\n",
       "2       hate  &#8220;@iamkrause: No need to thank me, killin...\n",
       "3  offensive  RT @tr4pb0y: when the pussy so good &amp; u fo...\n",
       "4  offensive     I talk to these bitches like I really do care."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example data\n",
    "\n",
    "train_df = pd.read_csv('./data/train.csv')\n",
    "val_df = pd.read_csv('./data/val.csv')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>RT @Black__Elvis: My favorite episode of Frien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hate</td>\n",
       "      <td>RT @TankTopshotta: A real nigga gone teach his...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hate</td>\n",
       "      <td>Shoot that nigga an his shorty bitch .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hate</td>\n",
       "      <td>@_XoXoKelsey_ hell naw fuck them bitches serve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@syd_renae okay cool then I'm not the only one...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "0  neutral  RT @Black__Elvis: My favorite episode of Frien...\n",
       "1     hate  RT @TankTopshotta: A real nigga gone teach his...\n",
       "2     hate             Shoot that nigga an his shorty bitch .\n",
       "3     hate  @_XoXoKelsey_ hell naw fuck them bitches serve...\n",
       "4  neutral  @syd_renae okay cool then I'm not the only one..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df['label'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>completion</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>offensive</td>\n",
       "      <td>RT @RAYCHIELOVESU: No &amp;#8220;@3rdeyechillin: T...</td>\n",
       "      <td>off</td>\n",
       "      <td>Classify the following messages into one of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>&amp;#8220;@__Black_Jesus: &amp;#8220;@lil_aerii: Happ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Classify the following messages into one of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hate</td>\n",
       "      <td>&amp;#8220;@iamkrause: No need to thank me, killin...</td>\n",
       "      <td>hate</td>\n",
       "      <td>Classify the following messages into one of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>offensive</td>\n",
       "      <td>RT @tr4pb0y: when the pussy so good &amp;amp; u fo...</td>\n",
       "      <td>off</td>\n",
       "      <td>Classify the following messages into one of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>offensive</td>\n",
       "      <td>I talk to these bitches like I really do care.</td>\n",
       "      <td>off</td>\n",
       "      <td>Classify the following messages into one of th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               text completion  \\\n",
       "0  offensive  RT @RAYCHIELOVESU: No &#8220;@3rdeyechillin: T...        off   \n",
       "1    neutral  &#8220;@__Black_Jesus: &#8220;@lil_aerii: Happ...    neutral   \n",
       "2       hate  &#8220;@iamkrause: No need to thank me, killin...       hate   \n",
       "3  offensive  RT @tr4pb0y: when the pussy so good &amp; u fo...        off   \n",
       "4  offensive     I talk to these bitches like I really do care.        off   \n",
       "\n",
       "                                              prompt  \n",
       "0  Classify the following messages into one of th...  \n",
       "1  Classify the following messages into one of th...  \n",
       "2  Classify the following messages into one of th...  \n",
       "3  Classify the following messages into one of th...  \n",
       "4  Classify the following messages into one of th...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can create prompt in 2 ways: instruction or raw text\n",
    "# For instruction propmpt we will use a human understandable textual instruction.\n",
    "# For raw prompt we will use raw text with special separator between propmpt and completion\n",
    "\n",
    "def create_instruction_prompt(text, all_labels):\n",
    "    prompt =  f'''Classify the following messages into one of the following categories: {', '.join(all_labels)}\n",
    "\n",
    "Message: {text}\n",
    "\n",
    "Category:'''\n",
    "    return prompt\n",
    "\n",
    "def create_raw_prompt(text):\n",
    "    prompt =  f'''{text} /n/n###/n/n'''\n",
    "    return prompt\n",
    "\n",
    "# For classification task we need 1 token completion. The completion token must be in model vocabulary. \n",
    "\n",
    "# GPTJ\n",
    "# GPTJ tokenization required completion tokens started with whitespace.\n",
    "\n",
    "# train_df['completion'] = train_df['label'].apply(lambda x: ' '+ x)\n",
    "# val_df['completion'] = val_df['label'].apply(lambda x: ' ' + x)\n",
    "\n",
    "#LLaMA\n",
    "to_replace = {'offensive': 'off'}\n",
    "train_df['completion'] = train_df['label'].replace(to_replace)\n",
    "val_df['completion'] = val_df['label'].replace(to_replace)\n",
    "\n",
    "# instruction based prompt\n",
    "all_labels = set(train_df['completion'].apply(lambda x: x.strip()).unique())\n",
    "train_df['prompt'] = train_df['text'].apply(lambda x: create_instruction_prompt(x, all_labels))\n",
    "val_df['prompt'] = val_df['text'].apply(lambda x: create_instruction_prompt(x, all_labels))\n",
    "\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training and validation samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'LLaMATokenizer'. \n",
      "The class this function is called from is 'LlamaTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "# Create torch Datasets with prepared finetuning samples\n",
    "\n",
    "# Load tokenizer and add padding token\n",
    "\n",
    "# GPTJ\n",
    "# tokenizer = transformers.AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\")\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# LLaMA\n",
    "tokenizer = transformers.LlamaTokenizer.from_pretrained(\n",
    "    \"decapoda-research/llama-7b-hf\", add_eos_token=False\n",
    ")\n",
    "\n",
    "# Define max_prompt_size. Used to pad short prompts and truncate large prompts. Need for batching or fitting VRAM.\n",
    "# We will take 0.99 quantile tokenized prompt length plus 1 token for completion. \n",
    "# Notice that we truncate only propmpt not completion.\n",
    "\n",
    "max_prompt_size = int(pd.Series(len(tokenizer.tokenize(e)) for e in (train_df['prompt'] + ' ' + train_df['completion'])).quantile(0.99)) + 1\n",
    "\n",
    "\n",
    "train_dataset = PromptDataset(train_df, tokenizer, max_prompt_len=max_prompt_size)\n",
    "val_dataset = PromptDataset(val_df, tokenizer, max_prompt_len=max_prompt_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning of the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 100\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvetka925\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74bd472b700841eb9cbe26d9dcde9771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016669246083332232, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20230406_105734-3ptgsv93</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vetka925/LLM_finetuning_hatetweets/runs/3ptgsv93' target=\"_blank\">LLaMA_7B_8BIT_attention_lora</a></strong> to <a href='https://wandb.ai/vetka925/LLM_finetuning_hatetweets' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vetka925/LLM_finetuning_hatetweets' target=\"_blank\">https://wandb.ai/vetka925/LLM_finetuning_hatetweets</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vetka925/LLM_finetuning_hatetweets/runs/3ptgsv93' target=\"_blank\">https://wandb.ai/vetka925/LLM_finetuning_hatetweets/runs/3ptgsv93</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fa30c10993f4f1f8e7d97d80c5ee843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/vetka/miniconda3/envs/transformers/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name  | Type                 | Params\n",
      "-----------------------------------------------\n",
      "0 | model | PeftModelForCausalLM | 6.7 B \n",
      "-----------------------------------------------\n",
      "2.1 M     Trainable params\n",
      "6.7 B     Non-trainable params\n",
      "6.7 B     Total params\n",
      "26,962.051Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c3c535d9cf422a9f06dd1ea25e83ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vetka/miniconda3/envs/transformers/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:488: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test/predict dataloaders.\n",
      "  rank_zero_warn(\n",
      "/home/vetka/miniconda3/envs/transformers/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/vetka/miniconda3/envs/transformers/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:232: UserWarning: You called `self.log('val_total_epoch_samples', ...)` in your `on_validation_epoch_end` but the value needs to be floating point. Converting it to torch.float32.\n",
      "  warning_cache.warn(\n",
      "/home/vetka/miniconda3/envs/transformers/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8de4d20c07ce45bd800dc4fa6e9de1ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f075315075d24649b65d99a1bf59c244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pl.seed_everything(100)\n",
    "\n",
    "# logging in wandb\n",
    "WANDB_PROJECT = \"LLM_finetuning_hatetweets\"\n",
    "RUN_NAME = 'LLaMA_7B_8BIT_attention_lora'\n",
    "wandb.login()\n",
    "wandb_logger = WandbLogger(project=WANDB_PROJECT, name=RUN_NAME)\n",
    "\n",
    "\n",
    "\n",
    "# Configuration\n",
    "config = FinetunerConfig(target_lora_modules=[\"q_proj\", \"v_proj\", \"o_proj\", \"k_proj\"],\n",
    "                        lr=1e-4, \n",
    "                        batch_size=2,\n",
    "                        num_epochs=3, \n",
    "                        adapter_dim=4,\n",
    "                        lora_dropout=0,\n",
    "                        lora_alpha=16,\n",
    "                        classification=True)\n",
    "\n",
    "\n",
    "# finetuner = GPTJ8bitFineTuner(\n",
    "#                                 model_name=GPTJ_6B_MODEL_PATH,\n",
    "#                                 fine_tuning_config=config, \n",
    "#                                 train_dataset=train_dataset,\n",
    "#                                 val_dataset=val_dataset)\n",
    "\n",
    "# finetuner = LLaMA4bitFineTuner(\n",
    "#                                 model_name=LLAMA_7B_MODEL_PATH,\n",
    "#                                 checkpoint_path='./llama-7b-4bit.pt',\n",
    "#                                 fine_tuning_config=config, \n",
    "#                                 train_dataset=train_dataset,\n",
    "#                                 val_dataset=val_dataset)\n",
    "\n",
    "finetuner = LLaMA8bitFineTuner(\n",
    "                                model_name=LLAMA_7B_MODEL_PATH,\n",
    "                                fine_tuning_config=config, \n",
    "                                train_dataset=train_dataset,\n",
    "                                val_dataset=val_dataset)\n",
    "\n",
    "finetuner.load()\n",
    "\n",
    "trainer = pl.Trainer(   logger=wandb_logger,    \n",
    "                        log_every_n_steps=1,  \n",
    "                        accelerator=\"gpu\",                \n",
    "                        max_epochs=config.num_epochs,\n",
    "                        enable_checkpointing=False,\n",
    "                    )\n",
    "\n",
    "trainer.fit(finetuner)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./loras'):\n",
    "    os.mkdir('loras')\n",
    "    \n",
    "finetuner.model.save_pretrained('./loras/llama_7B_8bit_hatespeech_classification')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune report\n",
    "\n",
    "[WanDB Report](https://api.wandb.ai/links/vetka925/qaqx6fhy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "924a3b04fe43f30915aa8df122b71dd508bc3d470b9e9ca76e559b1d5599b740"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
